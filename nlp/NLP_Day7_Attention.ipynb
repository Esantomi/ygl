{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Day7_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SOpsYjdWtfjE",
        "pPaInNB75_K4",
        "eDc-xtvBhm6C"
      ],
      "authorship_tag": "ABX9TyOjMTvR0E4G+ZMJY3xRapUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Esantomi/NLP/blob/master/NLP_Day7_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jhaunCzrgO4"
      },
      "source": [
        "RNN의 문제점  \n",
        "- 기울기 소실\n",
        "- 번역에는 사용하기 힘들다.\n",
        "  - 나는 점심을 먹는다.   \n",
        "  - I eat lunch  \n",
        "  - 각 언어별 어순 정보를 파악하기 힘들다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOpsYjdWtfjE"
      },
      "source": [
        "# seq2seq구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXl3MYabu2MN"
      },
      "source": [
        "## LSTM Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg7P1tLarZaN"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5csF-vt3uz1x"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = tf.keras.layers.LSTM(enc_units)\n",
        "    # return_sequences 매개변수를 기본값 False로 전달\n",
        "  def call(self, x):\n",
        "    print(\"입력 shape:\",x.shape)\n",
        "    \n",
        "    x=self.embedding(x)\n",
        "    print(\"Embedding Layer를 거친 shape \", x.shape)\n",
        "\n",
        "    output = self.lstm(x)\n",
        "    print(\"LSTM Layer의 Output Shape :\", output.shape)\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjVTLRspu69m",
        "outputId": "cafe8219-63b0-4ee9-f1b7-0b72422a19ca"
      },
      "source": [
        "vocab_size = 30000\n",
        "emb_size = 256\n",
        "lstm_size = 512\n",
        "batch_size = 1\n",
        "sample_seq_len = 3\n",
        "\n",
        "print(\"Vocab Size : {0}\".format(vocab_size))\n",
        "print(\"Embedding Size : {0}\".format(emb_size))\n",
        "print(\"LSTM size : {0}\".format(lstm_size))\n",
        "print(\"Batch Size : {0}\".format(batch_size))\n",
        "print(\"Sample Sequence Length : {0}\\n\".format(sample_seq_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab Size : 30000\n",
            "Embedding Size : 256\n",
            "LSTM size : 512\n",
            "Batch Size : 1\n",
            "Sample Sequence Length : 3\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O31yOu9pwlqa",
        "outputId": "bf70dacc-f79b-4829-d537-71ce6d40cee0"
      },
      "source": [
        "encoder = Encoder(vocab_size, emb_size, lstm_size)\n",
        "sample_input = tf.zeros((batch_size, sample_seq_len))\n",
        "\n",
        "sample_output = encoder(sample_input)\n",
        "# 컨텍스트 벡터로 사용한 인코더 LSTM의 최종 State값"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 shape: (1, 3)\n",
            "Embedding Layer를 거친 shape  (1, 3, 256)\n",
            "LSTM Layer의 Output Shape : (1, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_gYdYwGwqXw"
      },
      "source": [
        "![](https://aiffelstaticprd.blob.core.windows.net/media/images/GN-4-L-6.max-800x600.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEkHvnfrwtIY"
      },
      "source": [
        "## LSTM Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4xGgUBRwnNC"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = tf.keras.layers.LSTM(dec_units, return_sequences=True)\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "    self.softmax = tf.keras.layers.Softmax(axis= -1)\n",
        "\n",
        "  def call(self, x, context_v):\n",
        "    # 디코더의 입력 x와 인코더의 컨텍스트 벡터를 인자로 받습니다.\n",
        "    print(\"입력 shape :\", x.shape)\n",
        "\n",
        "    x = self.embedding(x)\n",
        "    print(\"Embedding Layer를 거친 Shape:\", x.shape)\n",
        "\n",
        "    context_v = tf.repeat(tf.expand_dims(context_v, axis=1), repeats=x.shape[1], axis =1)\n",
        "    x = tf.concat([x, context_v], axis = -1)\n",
        "    print(\"Context Vector가 더해진 Shape :\", x.shape)\n",
        "\n",
        "    x = self.lstm(x)\n",
        "    print(\"LSTM Layer의 Output Shape :\", x.shape)\n",
        "\n",
        "    output = self.fc(x)\n",
        "    print(\"Decoder 최종 Output Shape :\", output.shape)\n",
        "\n",
        "    return self.softmax(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtnSOi2y0CST",
        "outputId": "f1b5158f-51a6-46ad-897c-d1d1dfb54e8a"
      },
      "source": [
        "print(\"vocab Size : {0}\".format(vocab_size))\n",
        "print(\"Embedding Size : {0}\".format(emb_size))\n",
        "print(\"LSTM Size : {0}\".format(lstm_size))\n",
        "print(\"Batch Size : {0}\".format(batch_size))\n",
        "print(\"Sample Sequence Length : {0}\\n\".format(sample_seq_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab Size : 30000\n",
            "Embedding Size : 256\n",
            "LSTM Size : 512\n",
            "Batch Size : 1\n",
            "Sample Sequence Length : 3\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvyAdj9P0Dwb",
        "outputId": "34a52581-2d03-4727-9e2e-f69bc0feb0f8"
      },
      "source": [
        "decoder = Decoder(vocab_size, emb_size, lstm_size)\n",
        "sample_input = tf.zeros((batch_size, sample_seq_len))\n",
        "\n",
        "dec_output = decoder(sample_input, sample_output)\n",
        "# Decoder.call(x, context_v)를 호출"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 shape : (1, 3)\n",
            "Embedding Layer를 거친 Shape: (1, 3, 256)\n",
            "Context Vector가 더해진 Shape : (1, 3, 768)\n",
            "LSTM Layer의 Output Shape : (1, 3, 512)\n",
            "Decoder 최종 Output Shape : (1, 3, 30000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbRm4Kak0IuY"
      },
      "source": [
        "![](https://aiffelstaticprd.blob.core.windows.net/media/images/GN-4-L-7.max-800x600.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bx3VA7b54ey"
      },
      "source": [
        "- Rnn에 기반한 seq2seq 모델의 두 가지 문제점\n",
        "  1. 기울기 소실\n",
        "  2. 하나의 고정된 벡터에 모든 정보를 압축하려다 보니 정보 손실이 발생"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPaInNB75_K4"
      },
      "source": [
        "# 어텐션 메커니즘 (Attention Mechanism)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CyugqMq6Ihl"
      },
      "source": [
        "- 어텐션의 아이디어는 디코더에서 출력 단어를 예측하는 매 시점(time step)마다 인코더에서의 전체 입력 문장을 다시 한번 참고한다는 점\n",
        "- 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라, 해당 시점에서 예측해야 할 단어와 연관이 있는 입력 단어 부분을 좀 더 집중해서 본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2JmiuaI5-si"
      },
      "source": [
        "dict = {\"2017\": \"Transformer\", \"2018\":\"BERT\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDLhFH8M0E5a",
        "outputId": "089bae18-409a-4128-c97a-9ac470a38451"
      },
      "source": [
        "print(dict[\"2017\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transformer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw5iqny46R-R",
        "outputId": "cbc21674-ea43-4d9d-89d5-eeacd501bc78"
      },
      "source": [
        "print(dict[\"2018\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BERT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqZ79C6W8Ry1"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22893/%EC%BF%BC%EB%A6%AC.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmIxca4f8T5c"
      },
      "source": [
        "Attention(Q, K, V) = Attention Value\n",
        "- Query : t 시점의 디코더 셀에서의 은닉 상태\n",
        "- Key : 모든 시점의 인코더 셀의 은닉 상태\n",
        "- Value : 모든 시점의 인코더 셀의 은닉 상태"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1w8Ag4C8coM"
      },
      "source": [
        "## 닷 프로덕트 어텐션 (Dot-Product Attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O91hez98e9s"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22893/dotproductattention1_final.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vHVtKoO8jCt"
      },
      "source": [
        "### 1. 어텐션 스코어 구하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YsXZckF8oIN"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22893/dotproductattention2_final.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhWnOEvR81sV"
      },
      "source": [
        "$$score(s_t, h_i) = S_t^T h_i $$  \n",
        "$$e^t = [s_t^T h_1, ..., s_t^T h_N]$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5JxWMPF8o2N"
      },
      "source": [
        "### 2. 소프트맥스(softmax) 함수를 통해 어텐션 분포를 구함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFHbRm1P84LW"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22893/dotproductattention3_final.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72jOZ9O4AOLB"
      },
      "source": [
        "$$a^t = softmax(e^t)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cD9tvYp8tt2"
      },
      "source": [
        "### 3. 각 인코더의 어텐션 가중치와 은닉 상태를 가중합하여 어텐션 값을 구함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2gREtjK8w1l"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22893/dotproductattention4_final.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW7VCQFeARQr"
      },
      "source": [
        "$$a_t = \\sum_{i=1}^{N}{a_i^th_i}$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD23tGo4ARZN"
      },
      "source": [
        "### 4. 어텐션 값과 디코더의 t 시점의 은닉 상태를 연결"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1VmfFKRAXO8"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22893/dotproductattention5_final_final.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9sz66zhAX9b"
      },
      "source": [
        "### 5. 출력층 연산의 입력이 되는 st를 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTAsPbwfAYAL"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22893/st.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPjZzLBnAb8E"
      },
      "source": [
        "$$ \\tilde{s_{t}}=tanh(W_c[a_t ; s_t] + b_c)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXm8ZGGLAfRs"
      },
      "source": [
        "### 6. st를 출력층의 입력으로 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjIXlpO3AgJc"
      },
      "source": [
        "$$ \\hat{y_t}=Softmax(W_y\\tilde{s_t}+b_y)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvwLKp3bluQQ"
      },
      "source": [
        "### Bahdanau Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B4-MmCoAgPf"
      },
      "source": [
        "- Bahdanau Attention\n",
        "$$ Score_{alignment} = W * tanh(W_{decoder} * H_{decoder} + W_{encoder} * H_{encoder}) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tod9Oa9R6TC5",
        "outputId": "8a5cd2a0-f8cf-4e33-d59d-a7258f69f2b4"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W_decoder = tf.keras.layers.Dense(units)\n",
        "    self.W_encoder = tf.keras.layers.Dense(units)\n",
        "    self.W_combine = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, H_encoder, H_decoder):\n",
        "    print(\"[H_encoder] Shape :\", H_encoder.shape)\n",
        "\n",
        "    H_encoder = self.W_encoder(H_encoder)\n",
        "    print(\"[W_encoder X H_encoder] Shape:\", H_encoder.shape)\n",
        "\n",
        "    print(\"\\n[H_decoder] Shape: \", H_decoder.shape)\n",
        "    H_decoder = tf.expand_dims(H_decoder, 1)\n",
        "    H_decoder = self.W_decoder(H_decoder)\n",
        "\n",
        "    print(\"[W_decoder X H_decoder] Shape:\", H_decoder.shape)\n",
        "\n",
        "    score = self.W_combine(tf.nn.tanh(H_decoder+H_encoder))\n",
        "    print(\"[Score_alignment]Shape :\", score.shape)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(score, axis = 1)\n",
        "    print(\"\\n최종 weight : \\n\", attention_weights.numpy())\n",
        "\n",
        "    context_vector = attention_weights * H_decoder\n",
        "    context_vector = tf.reduce_sum(context_vector, axis = 1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "\n",
        "W_size = 100\n",
        "\n",
        "print(\"Hidden State를 {0}차원으로 Mapping\\n\".format(W_size))\n",
        "\n",
        "attention = BahdanauAttention(W_size)\n",
        "\n",
        "enc_state = tf.random.uniform((1, 10, 512))\n",
        "dec_state = tf.random.uniform((1, 512))\n",
        "\n",
        "_ = attention(enc_state, dec_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hidden State를 100차원으로 Mapping\n",
            "\n",
            "[H_encoder] Shape : (1, 10, 512)\n",
            "[W_encoder X H_encoder] Shape: (1, 10, 100)\n",
            "\n",
            "[H_decoder] Shape:  (1, 512)\n",
            "[W_decoder X H_decoder] Shape: (1, 1, 100)\n",
            "[Score_alignment]Shape : (1, 10, 1)\n",
            "\n",
            "최종 weight : \n",
            " [[[0.07395881]\n",
            "  [0.09009522]\n",
            "  [0.06064911]\n",
            "  [0.16680424]\n",
            "  [0.17511545]\n",
            "  [0.08980763]\n",
            "  [0.08080629]\n",
            "  [0.08456039]\n",
            "  [0.10162464]\n",
            "  [0.07657818]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw1HdxzhEJif"
      },
      "source": [
        "![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/GN-4-L-9.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcIhsCpxELcL"
      },
      "source": [
        "### Loung Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H657oYJMEP_q"
      },
      "source": [
        "$$ Score(H_{target},H_{source}) = H_{target}^T * W_{combine} * H_{source})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_fQugvxEHCy",
        "outputId": "7a8107c6-aec9-41c5-85fd-112e2434b268"
      },
      "source": [
        "class LuongAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(LuongAttention, self).__init__()\n",
        "    self.W_combine = tf.keras.layers.Dense(units)\n",
        "  \n",
        "  def call(self, H_encoder, H_decoder):\n",
        "    print(\"[H_encoder] shape: \", H_encoder.shape)\n",
        "\n",
        "    WH = self.W_combine(H_encoder)\n",
        "    print(\"[W_encoder X H_encoder] shape :\", WH.shape)\n",
        "\n",
        "    H_decoder = tf.expand_dims(H_decoder, 1)\n",
        "    alignment = tf.matmul(WH, tf.transpose(H_decoder, [0, 2, 1]))\n",
        "    print(\"[Score_alignment] Shape :\", alignment.shape)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(alignment, axis = 1)\n",
        "    print(\"\\n최종 weight : \\n\", attention_weights.numpy())\n",
        "\n",
        "    attention_weights = tf.squeeze(attention_weights, axis = -1)\n",
        "    context_vector = tf.matmul(attention_weights, H_encoder)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "\n",
        "emb_dim = 512\n",
        "\n",
        "attention = LuongAttention(emb_dim)\n",
        "\n",
        "enc_state = tf.random.uniform((1, 10, emb_dim))\n",
        "dec_state = tf.random.uniform((1, emb_dim))\n",
        "\n",
        "_ = attention(enc_state, dec_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[H_encoder] shape:  (1, 10, 512)\n",
            "[W_encoder X H_encoder] shape : (1, 10, 512)\n",
            "[Score_alignment] Shape : (1, 10, 1)\n",
            "\n",
            "최종 weight : \n",
            " [[[9.9635776e-03]\n",
            "  [3.5920415e-02]\n",
            "  [1.1699638e-02]\n",
            "  [7.3278522e-01]\n",
            "  [6.3557647e-02]\n",
            "  [2.2391758e-03]\n",
            "  [4.2902087e-05]\n",
            "  [2.4874238e-03]\n",
            "  [1.5677591e-03]\n",
            "  [1.3973625e-01]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDc-xtvBhm6C"
      },
      "source": [
        "# 양방향 LSTM과 어텐션 메커니즘 (IMDb 리뷰 데이터)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl5A0Y-Ch4Lq"
      },
      "source": [
        "## IMDB 리뷰 데이터 전처리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stztNG5bG7VP"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPPh6Tp1h7cz",
        "outputId": "03d464bb-924e-4501-8eb0-ebd90ef89e95"
      },
      "source": [
        "vocab_size = 10000\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOLY3c8uh8iK",
        "outputId": "4e6d8271-289a-414a-df0b-3dd95dc4c0d2"
      },
      "source": [
        "print('리뷰의 최대 길이 : {}'.format(max(len(l) for l in x_train)))\n",
        "print('리뷰의 평균 길이 : {}'.format(sum(map(len, x_train))/len(x_train)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 2494\n",
            "리뷰의 평균 길이 : 238.71364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHxIvH7pif6g"
      },
      "source": [
        "max_len = 500\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Qibhv3iuJX"
      },
      "source": [
        "## 바다나우 어텐션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN2xTTo0i1l8"
      },
      "source": [
        "$$score(query, key) = V^Ttanh(W_1 key + W_2 query)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrzuhz4rihPp"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrUpk4nGi3D7"
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1)\n",
        "\n",
        "  def call(self, values, query): \n",
        "    #query size (batch_size, hidden size)\n",
        "    # hidde_with time axis shape (batch size, 1, hidden_size)\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention weights shape == (batch size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis =1 )\n",
        "\n",
        "    # context_vector shape after sum == (batch size, hidden size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK0j2PuLkO1F"
      },
      "source": [
        "## 양방향 LSTM + 어텐션 메커니즘"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a_WuRYmkMNk"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras import optimizers\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkSUcRIwkTbT"
      },
      "source": [
        "sequence_input = Input(shape =(max_len, ), dtype='int32')\n",
        "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len, mask_zero = True)(sequence_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si597fZdlZJj"
      },
      "source": [
        "lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences=True))(embedded_sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UusMwo4laK7"
      },
      "source": [
        "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LML-1KbClbET",
        "outputId": "b093b91b-6e2c-4a8d-df8f-ddb7cb0963f6"
      },
      "source": [
        "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 500, 128) (None, 64) (None, 64) (None, 64) (None, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJivKDvslb7T"
      },
      "source": [
        "state_h = Concatenate()([forward_h, backward_h])\n",
        "state_c = Concatenate()([forward_c, backward_c])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcfonSetmKRM"
      },
      "source": [
        "attention = BahdanauAttention(64)  # 가중치의 크기 정의\n",
        "context_vector, attention_weights = attention(lstm, state_h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npBZ3HtCmL5g"
      },
      "source": [
        "dense1 = Dense(20, activation='relu')(context_vector)\n",
        "dropout = Dropout(0.5)(dense1)\n",
        "output = Dense(1,activation=\"sigmoid\")(dropout)\n",
        "model = Model(inputs=sequence_input, outputs = output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs6jVF8_mphT"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFRhy0XPoxZT",
        "outputId": "70315d61-8239-4818-adb0-ca41dde58a00"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=5, batch_size=256, validation_data=(x_test, y_test), verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "98/98 [==============================] - 543s 5s/step - loss: 0.5059 - accuracy: 0.7366 - val_loss: 0.2964 - val_accuracy: 0.8776\n",
            "Epoch 2/5\n",
            "98/98 [==============================] - 522s 5s/step - loss: 0.2677 - accuracy: 0.9070 - val_loss: 0.2922 - val_accuracy: 0.8791\n",
            "Epoch 3/5\n",
            "98/98 [==============================] - 509s 5s/step - loss: 0.2025 - accuracy: 0.9353 - val_loss: 0.3198 - val_accuracy: 0.8774\n",
            "Epoch 4/5\n",
            "98/98 [==============================] - 506s 5s/step - loss: 0.1789 - accuracy: 0.9446 - val_loss: 0.3713 - val_accuracy: 0.8694\n",
            "Epoch 5/5\n",
            "98/98 [==============================] - 503s 5s/step - loss: 0.1454 - accuracy: 0.9594 - val_loss: 0.3643 - val_accuracy: 0.8682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xptyA3WWp_ok",
        "outputId": "c6478a3f-5b92-4fe0-a78d-74a8547f86e8"
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(x_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 329s 421ms/step - loss: 0.3643 - accuracy: 0.8682\n",
            "\n",
            " 테스트 정확도: 0.8682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GCGAwlX2FEO"
      },
      "source": [
        "# seq2seq with attention 스페인-영어 번역기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbxPkqVO6GNi"
      },
      "source": [
        "## 데이터 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68jnDEsG16Ha"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFp5eTVU5v4H"
      },
      "source": [
        "path_to_zip = tf.keras.utils.get_file('spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip', extract=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB4An1C35xJt"
      },
      "source": [
        "path_to_file = os.path.dirname(path_to_zip)+ \"/spa-eng/spa.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvUCvhAF5yp-",
        "outputId": "054296b0-3de0-4dd4-ee80-a22c61a9036d"
      },
      "source": [
        "with open(path_to_file, \"r\") as f:\n",
        "  raw = f.read().splitlines()\n",
        "\n",
        "print(\"Data Size: \", len(raw))\n",
        "print(\"Example:\")\n",
        "\n",
        "for sen in raw[0:100][::20]: print(\">>\", sen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Size:  118964\n",
            "Example:\n",
            ">> Go.\tVe.\n",
            ">> Wait.\tEsperen.\n",
            ">> Hug me.\tAbrázame.\n",
            ">> No way!\t¡Ni cagando!\n",
            ">> Call me.\tLlamame.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay8Ej4xk6MRG"
      },
      "source": [
        "## 데이터 전처리 : 정제하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDZAZ0ha6KJJ"
      },
      "source": [
        "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
        "    sentence = sentence.lower().strip()\n",
        "\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    if s_token:\n",
        "        sentence = '<start> ' + sentence\n",
        "\n",
        "    if e_token:\n",
        "        sentence += ' <end>'\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc7vfxuM7ATe",
        "outputId": "cecb734e-92e3-411b-d071-a4997d47a433"
      },
      "source": [
        "eng_corpus = []\n",
        "dec_corpus = []\n",
        "\n",
        "num_examples = 30000\n",
        "\n",
        "for pair in raw[:num_examples]:\n",
        "  eng, spa = pair.split(\"\\t\")\n",
        "\n",
        "  eng_corpus.append(preprocess_sentence(eng))\n",
        "  dec_corpus.append(preprocess_sentence(spa, s_token=True, e_token=True))\n",
        "\n",
        "print(\"English :\", eng_corpus[100])\n",
        "print(\"Spanish :\", dec_corpus[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English : go away !\n",
            "Spanish : <start> salga de aqu ! <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kif2D4aO8XY-"
      },
      "source": [
        "## 데이터 전처리 : 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz-w3Nin8Qx6"
      },
      "source": [
        "def tokenize(corpus):\n",
        "  tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "  tensor = tokenizer.texts_to_sequences(corpus)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "  return tensor, tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tkfbe_fL857F"
      },
      "source": [
        "# 토큰화 하기\n",
        "# 훈련 데이터와 검증 데이터로 분리하기\n",
        "# 정제된 텍스트를 아래 tokenize() 함수를 사용해 토큰화해서 텐서로 변환하세요~\n",
        "\n",
        "enc_tensor, enc_tokenizer = tokenize(eng_corpus)\n",
        "dec_tensor, dec_tokenizer = tokenize(dec_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-d3E6kx871H"
      },
      "source": [
        "# 그리고 변환된 텐서를 80%의 훈련데이터와 20% 검증데이터로 분리하세요\n",
        "# 단 Tokenizer의 단어 수는 자유롭게 진행하세요!\n",
        "\n",
        "enc_train, enc_val, dec_train, dec_val = train_test_split(enc_tensor, dec_tensor, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Jq7-qE92Sa",
        "outputId": "76a5b32f-0808-4afd-b574-46fddee36c25"
      },
      "source": [
        "# english vocab size반환\n",
        "# spanish vocab size반환\n",
        "\n",
        "print('English Vocab Size :',len(enc_tokenizer.index_word))\n",
        "print('Spanish Vocab Size :',len(dec_tokenizer.index_word))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocab Size : 4931\n",
            "Spanish Vocab Size : 8893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWIpNrXU-pMh"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.w_dec = tf.keras.layers.Dense(units)\n",
        "    self.w_enc = tf.keras.layers.Dense(units)\n",
        "    self.w_com = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, h_enc, h_dec):\n",
        "    # h_enc shape : [batch x length x units]\n",
        "    # h_dec shape : [batch x units]\n",
        "\n",
        "    h_enc = self.w_enc(h_enc)\n",
        "    h_dec = tf.expand_dims(h_dec, 1)\n",
        "    h_dec = self.w_dec(h_dec)\n",
        "\n",
        "    score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
        "\n",
        "    attn = tf.nn.softmax(score, axis =1)\n",
        "\n",
        "    context_vec = attn * h_enc\n",
        "    context_vec = tf.reduce_sum(context_vec, axis=1)\n",
        "    return context_vec, attn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vpha0b8_z0b"
      },
      "source": [
        "![](https://aiffelstaticprd.blob.core.windows.net/media/images/GN-4-P-2.max-800x600.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OAHjDOM_YuG"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    # todo\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(enc_units, return_sequences=True)\n",
        "\n",
        "  def call(self, x):\n",
        "    # todo \n",
        "    out = self.embedding(x)\n",
        "    out = self.gru(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gvrugsy_15N"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    # To do\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(dec_units, return_sequences=True, return_state=True)\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, h_dec, enc_out):\n",
        "    # To do\n",
        "    context_vec, attn = self.attention(enc_out, h_dec)\n",
        "    \n",
        "    out = self.embedding(x)\n",
        "    out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
        "\n",
        "    out, h_dec = self.gru(out)\n",
        "    out = tf.reshape(out, (-1, out.shape[2]))\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out, h_dec, attn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQoqfYgxH1n7",
        "outputId": "e945a0f3-225a-40f3-8b50-ea180de01ea9"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "src_vocab_size = len(enc_tokenizer.index_word) + 1\n",
        "tgt_vocab_size = len(dec_tokenizer.index_word) + 1\n",
        "\n",
        "units = 1024\n",
        "embedding_dim = 512\n",
        "\n",
        "encoder = Encoder(src_vocab_size, embedding_dim, units)\n",
        "decoder = Decoder(tgt_vocab_size, embedding_dim, units)\n",
        "\n",
        "# sample input\n",
        "sequence_len = 30\n",
        "\n",
        "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
        "sample_output = encoder(sample_enc)\n",
        "\n",
        "print('Encoder Output:', sample_output.shape)\n",
        "\n",
        "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
        "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_state, sample_output)\n",
        "\n",
        "print('Decoder output :', sample_logits.shape)\n",
        "print('Decoder Hidden State :', h_dec.shape)\n",
        "print('Attention :', attn.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder Output: (64, 30, 1024)\n",
            "Decoder output : (64, 8894)\n",
            "Decoder Hidden State : (64, 1024)\n",
            "Attention : (64, 30, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXpgpFjfMiqO"
      },
      "source": [
        "## 훈련하기 1. Optimizer & loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liM8YKrKKONN"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "# Categorical Crossentropy()\n",
        "# [0.1, 0.2, 0.7] --> onehot encoding [0, 0, 1]\n",
        "# SparseCategoricalCrossentropy()\n",
        "# [0.1, 0.2, 0.7] ---> 정수 인덱스 2\n",
        "# True --> 모델의 출력값을 그대로 전달\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYUmX5ReNTJG"
      },
      "source": [
        "## 훈련하기 2. train_step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oIEp0RnNRa8"
      },
      "source": [
        "@tf.function\n",
        "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
        "  bsz = src.shape[0]\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_out = encoder(src)\n",
        "    h_dec = enc_out[:, -1]\n",
        "\n",
        "    dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
        "\n",
        "    for t in range(1, tgt.shape[1]):\n",
        "      pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
        "\n",
        "      loss += loss_function(tgt[:, t], pred)\n",
        "      dec_src = tf.expand_dims(tgt[:,t], 1)\n",
        "\n",
        "  batch_loss = (loss/int(tgt.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixJyOvEqOpjA"
      },
      "source": [
        "- train_step 학습과정\n",
        "  1. Encoder에 소스 문장을 전달해 컨텍스트 벡터인 enc_out을 생성\n",
        "  2. Decoder에 입력으로 전달할 <start>토큰 문장 생성\n",
        "  3. t=0일때, Decoder의 Hidden State는 Encoder의 Final State로 정의. h_dec = enc_out[:, -1]\n",
        "  4. <start>문장과 enc_out, Hidden State를 기반으로 다음단어 (t=1)예측. pred\n",
        "  5. 예측된 단어와 정답 간의 Loss를 구한 후, t=1의 정답 단어를 다음 입력으로 사용 (예측단어X)\n",
        "  6. 반복!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOXHJSoJOkG2",
        "outputId": "4a506c87-f6c3-403b-9809-5ef408e384b4"
      },
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQX7iiKsOxo2",
        "outputId": "41dadd62-d805-4819-aebb-9038aca232ba"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "\n",
        "  idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "  random.shuffle(idx_list)\n",
        "  t = tqdm(idx_list)\n",
        "\n",
        "  for (batch, idx) in enumerate(t):\n",
        "    batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
        "                            dec_train[idx:idx+BATCH_SIZE],\n",
        "                            encoder,\n",
        "                            decoder,\n",
        "                            optimizer,\n",
        "                            dec_tokenizer)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    t.set_description_str('Epoch %2d' % (epoch+1))\n",
        "    t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch+1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1: 100%|██████████| 375/375 [27:55<00:00,  4.47s/it, Loss 1.3469]\n",
            "Epoch  2: 100%|██████████| 375/375 [27:34<00:00,  4.41s/it, Loss 0.8852]\n",
            "Epoch  3: 100%|██████████| 375/375 [27:22<00:00,  4.38s/it, Loss 0.6249]\n",
            "Epoch  4: 100%|██████████| 375/375 [27:46<00:00,  4.44s/it, Loss 0.4476]\n",
            "Epoch  5: 100%|██████████| 375/375 [27:31<00:00,  4.40s/it, Loss 0.3291]\n",
            "Epoch  6: 100%|██████████| 375/375 [27:50<00:00,  4.45s/it, Loss 0.2565]\n",
            "Epoch  7: 100%|██████████| 375/375 [28:21<00:00,  4.54s/it, Loss 0.2079]\n",
            "Epoch  8: 100%|██████████| 375/375 [28:34<00:00,  4.57s/it, Loss 0.1769]\n",
            "Epoch  9: 100%|██████████| 375/375 [27:48<00:00,  4.45s/it, Loss 0.1549]\n",
            "Epoch 10: 100%|██████████| 375/375 [27:54<00:00,  4.47s/it, Loss 0.1404]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsUUJhWsS6bj"
      },
      "source": [
        "## Evaluation step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpvacnhaQBkv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "629233fb-c79d-4f20-f55a-7bac4be35866"
      },
      "source": [
        "@tf.function\n",
        "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
        "    bsz = src.shape[0]\n",
        "    loss = 0\n",
        "\n",
        "    enc_out = encoder(src)\n",
        "\n",
        "    h_dec = enc_out[:, -1]\n",
        "    \n",
        "    dec_src = tf.expand_dims([dec_tok.word_index['']] * bsz, 1)\n",
        "\n",
        "    for t in range(1, tgt.shape[1]):\n",
        "        pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
        "\n",
        "        loss += loss_function(tgt[:, t], pred)\n",
        "        dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "        \n",
        "    batch_loss = (loss / int(tgt.shape[1]))\n",
        "    \n",
        "    return batch_loss\n",
        "\n",
        "\n",
        "# Training Process\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    \n",
        "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
        "                                dec_train[idx:idx+BATCH_SIZE],\n",
        "                                encoder,\n",
        "                                decoder,\n",
        "                                optimizer,\n",
        "                                dec_tokenizer)\n",
        "    \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
        "    \n",
        "    test_loss = 0\n",
        "    \n",
        "    idx_list = list(range(0, enc_val.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (test_batch, idx) in enumerate(t):\n",
        "        test_batch_loss = eval_step(enc_val[idx:idx+BATCH_SIZE],\n",
        "                                    dec_val[idx:idx+BATCH_SIZE],\n",
        "                                    encoder,\n",
        "                                    decoder,\n",
        "                                    dec_tokenizer)\n",
        "    \n",
        "        test_loss += test_batch_loss\n",
        "\n",
        "        t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1: 100%|██████████| 375/375 [28:08<00:00,  4.50s/it, Loss 0.1279]\n",
            "  0%|          | 0/94 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2600251e27ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m                                     \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                                     \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                     dec_tokenizer)\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtest_batch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: in user code:\n\n    <ipython-input-19-2600251e27ee>:10 eval_step  *\n        dec_src = tf.expand_dims([dec_tok.word_index['']] * bsz, 1)\n\n    KeyError: ''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yI_eIwJNTCtT"
      },
      "source": [
        "## Attention Map 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KlK-0l8TFC8"
      },
      "source": [
        "def evaluate(sentence, encoder, decoder):\n",
        "    attention = np.zeros((dec_train.shape[-1], enc_train.shape[-1]))\n",
        "    \n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    inputs = enc_tokenizer.texts_to_sequences([sentence.split()])\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                           maxlen=enc_train.shape[-1],\n",
        "                                                           padding='post')\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    enc_out = encoder(inputs)\n",
        "\n",
        "    dec_hidden = enc_out[:, -1]\n",
        "    dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(dec_train.shape[-1]):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = \\\n",
        "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
        "\n",
        "        result += dec_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention\n",
        "\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def translate(sentence, encoder, decoder):\n",
        "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    \n",
        "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
        "    plot_attention(attention, sentence.split(), result.split(' '))\n",
        "\n",
        "\n",
        "translate(\"Can I have some coffee?\", encoder, decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x36MgT0wTLSk"
      },
      "source": [
        "![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/GN-4-P-3.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1aAKAqgTN6N"
      },
      "source": [
        "# 주말 동안 공부해야 할 숙제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uerts8jZUOlQ"
      },
      "source": [
        "한-영 번역기 만들기\n",
        "한-영 번역기 만들기\n",
        "1. 데이터 다운로드\n",
        "- 데이터 : https://github.com/jungyeul/korean-parallel-corpora/tree/master/korean-english-news-v1\n",
        "- korean-english-park.train.tar.gz\n",
        "2. 데이터 정제\n",
        "- set 데이터형이 중복이 허용하지 않다는 것을 활용해 중복된 데이터를 제거\n",
        "  - 데이터 병렬 쌍이 흐트러지지 않게 주의!\n",
        "  - cleaned_corpus에 저장\n",
        "- 앞서 정의한 preprocessing()함수는 한글에 대해 동작하지 않아요.\n",
        "  - 한글에 적용할 수 있는 정규식을 추가해여 함수를 재정의 하세요.\n",
        "- 타겟 언어인 영문엔 <start>토큰과 <end>토큰을 추가하고 split()함수로 토큰화 합니다. 한글 토큰화는 konlpy의 mecab클래스를 사용합니다.\n",
        "  - cleaned_corpus로부터 토큰의길이가 40이하인 데이터를 선별하여 eng_corpus와 kor_corpus를 각각 구축하기\n",
        "\n",
        "3. 토큰화\n",
        "- tokenize()함수를 사용해 데이터를 텐서로 변환하고 각각의 tokenizer를 얻으세요!\n",
        "  - 단어수는 실험을 통해 적당한 값을 맞춰줍시다(최소 10000이상!)\n",
        "4. 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNmtZqvvU0CH"
      },
      "source": [
        "```\n",
        "sudo apt -qq -y install fonts-nanum\n",
        "```"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWGBBbHIUv7J"
      },
      "source": [
        "```\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "%config InlineBackend.figure_format = 'retina'\n",
        " \n",
        "import matplotlib.font_manager as fm\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager._rebuild()\n",
        "```"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}