{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Day6_seq2seqTranslator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNEUNMP9TrgSUN14738jr4r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Esantomi/NLP/blob/master/NLP_Day6_seq2seqTranslator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nM6bhr64s2l"
      },
      "source": [
        "# 글자 단위(Character-level)로 구현한 seq2seq 번역기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57lHj2_54Bak",
        "outputId": "0bca4485-d8c5-4540-f3f7-0b462fc5ab68"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj2znySQ57jz"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "k6guWITb461y",
        "outputId": "a2040f29-c870-4ad1-e0ac-8f0b21d4bc34"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "file_path = './fra.txt'\n",
        "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
        "lines.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "      <th>cc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>162262</th>\n",
              "      <td>There are frequently earthquakes in Japan.</td>\n",
              "      <td>Il y a fréquemment des tremblements de terre a...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162680</th>\n",
              "      <td>What would you do if you were in my place?</td>\n",
              "      <td>Que feriez-vous à ma place ?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181668</th>\n",
              "      <td>My parents have gone to the airport to see my ...</td>\n",
              "      <td>Mes parents sont partis à l'aéroport pour dire...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181995</th>\n",
              "      <td>All schoolchildren are half price during Chris...</td>\n",
              "      <td>Tous les écoliers sont à moitié prix pendant l...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43930</th>\n",
              "      <td>Tom asked a question.</td>\n",
              "      <td>Tom posa une question.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      eng  ...                                                 cc\n",
              "162262         There are frequently earthquakes in Japan.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #4...\n",
              "162680         What would you do if you were in my place?  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "181668  My parents have gone to the airport to see my ...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "181995  All schoolchildren are half price during Chris...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "43930                               Tom asked a question.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Y7gfSRgh5jCo",
        "outputId": "ec7fd50b-62e4-45e6-aa73-67559de4f7e7"
      },
      "source": [
        "lines = lines[['eng', 'fra']][:50000] #5만개 샘플사용\n",
        "lines.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4360</th>\n",
              "      <td>Can we start?</td>\n",
              "      <td>Pouvons-nous commencer ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8595</th>\n",
              "      <td>Tom needs you.</td>\n",
              "      <td>Tom a besoin de toi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7471</th>\n",
              "      <td>I'm beautiful.</td>\n",
              "      <td>Je suis beau.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30686</th>\n",
              "      <td>That's good enough.</td>\n",
              "      <td>C'est suffisamment bon.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31756</th>\n",
              "      <td>We all felt hungry.</td>\n",
              "      <td>Nous avions tous faim.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       eng                       fra\n",
              "4360         Can we start?  Pouvons-nous commencer ?\n",
              "8595        Tom needs you.      Tom a besoin de toi.\n",
              "7471        I'm beautiful.             Je suis beau.\n",
              "30686  That's good enough.   C'est suffisamment bon.\n",
              "31756  We all felt hungry.    Nous avions tous faim."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "kpb2JE_T6JZF",
        "outputId": "7a9c0a6b-f960-4d28-ed0b-30ebea608f47"
      },
      "source": [
        "# 시작 토큰과 종료 토큰 추가\n",
        "sos_token = '\\t'  # start-of-string\n",
        "eos_token = '\\n'  # end-of-string\n",
        "lines.fra = lines.fra.apply(lambda x: '\\t' + x + '\\n')\n",
        "\n",
        "print('전체 샘플의 수 :',len(lines))\n",
        "lines.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 수 : 50000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4386</th>\n",
              "      <td>Come join us.</td>\n",
              "      <td>\\tVenez vous joindre à nous !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1689</th>\n",
              "      <td>Come alone.</td>\n",
              "      <td>\\tVenez seuls !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16410</th>\n",
              "      <td>You can come in.</td>\n",
              "      <td>\\tTu peux entrer.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9046</th>\n",
              "      <td>You can do it.</td>\n",
              "      <td>\\tVous pouvez le faire.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27837</th>\n",
              "      <td>Get real, will you?</td>\n",
              "      <td>\\tSoyez réaliste, voulez-vous ?\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       eng                                fra\n",
              "4386         Come join us.    \\tVenez vous joindre à nous !\\n\n",
              "1689           Come alone.                  \\tVenez seuls !\\n\n",
              "16410     You can come in.                \\tTu peux entrer.\\n\n",
              "9046        You can do it.          \\tVous pouvez le faire.\\n\n",
              "27837  Get real, will you?  \\tSoyez réaliste, voulez-vous ?\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfhTAsSu6s2j",
        "outputId": "51683245-9f4c-4c6c-f7c9-98b183213bfc"
      },
      "source": [
        "eng_tokenizer = Tokenizer(char_level=True)\n",
        "# 글자 단위로 토큰화\n",
        "\n",
        "eng_tokenizer.fit_on_texts(lines.eng)\n",
        "# 50000개의 행을 가진 eng의 각 행에 토큰화 수행\n",
        "\n",
        "input_text = eng_tokenizer.texts_to_sequences(lines.eng)\n",
        "# 단어를 숫자값 인덱스로 변환하여 저장\n",
        "\n",
        "input_text[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[19, 3, 8], [19, 3, 8], [19, 3, 8]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5jIPzWv7jr1",
        "outputId": "1ba4f148-b2bb-44a7-d74a-7f2ce38ea438"
      },
      "source": [
        "fra_tokenizer = Tokenizer(char_level=True)\n",
        "# 글자 단위로 토큰화\n",
        "\n",
        "fra_tokenizer.fit_on_texts(lines.fra)\n",
        "# 50000개의 행을 가진 eng의 각 행에 토큰화 수행\n",
        "\n",
        "target_text = fra_tokenizer.texts_to_sequences(lines.fra)\n",
        "# 단어를 숫자값 인덱스로 변환하여 저장\n",
        "\n",
        "target_text[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[10, 19, 5, 1, 31, 11],\n",
              " [10, 15, 5, 12, 16, 29, 2, 14, 11],\n",
              " [10, 26, 9, 8, 28, 2, 1, 31, 11]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnrfDhlG7lDA",
        "outputId": "6d2b9cc1-90ee-4279-d641-e74fb58bf31e"
      },
      "source": [
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
        "\n",
        "print('영어 단어장의 크기 :',eng_vocab_size)\n",
        "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 단어장의 크기 : 52\n",
            "프랑스어 단어장의 크기 : 73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqV6gLLS70Ok",
        "outputId": "3a10a7b2-3ce1-43d5-d15e-37223bfaf998"
      },
      "source": [
        "max_eng_seq_len = max([len(line) for line in input_text])\n",
        "max_fra_seq_len = max([len(line) for line in target_text])\n",
        "\n",
        "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
        "print('프랑스 시퀀스의 최대 길이', max_fra_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 시퀀스의 최대 길이 22\n",
            "프랑스 시퀀스의 최대 길이 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE9Biaha8Gqm",
        "outputId": "ae4a0917-4929-4582-a28c-113ab43e1e88"
      },
      "source": [
        "# 한번에 출력\n",
        "print('전체 샘플의 수 :', len(lines))\n",
        "print('영어 단어장의 크기:', eng_vocab_size)\n",
        "print('프랑스어 단어장의 크기:', fra_vocab_size)\n",
        "print('영어 시퀀스의 최대 길이:', max_eng_seq_len)\n",
        "print('프랑스 시퀀스의 최대 길이', max_fra_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 수 : 50000\n",
            "영어 단어장의 크기: 52\n",
            "프랑스어 단어장의 크기: 73\n",
            "영어 시퀀스의 최대 길이: 22\n",
            "프랑스 시퀀스의 최대 길이 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGPHRl0T8eUy"
      },
      "source": [
        "encoder_input = input_text\n",
        "\n",
        "# 종료 토큰 제거\n",
        "decoder_input = [[char for char in line if char != fra_tokenizer.word_index[eos_token]] for line in target_text]\n",
        "\n",
        "# 시작 토큰 제거\n",
        "decoder_target = [[char for char in line if char != fra_tokenizer.word_index[sos_token]] for line in target_text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLHNsOdy9Php",
        "outputId": "3fb5c6a9-f4ce-4016-ffa6-3d7266fd7766"
      },
      "source": [
        "print(decoder_input[:3])  # <eos>토큰 제거\n",
        "print(decoder_target[:3])  # <sos>토큰 제거"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10, 19, 5, 1, 31], [10, 15, 5, 12, 16, 29, 2, 14], [10, 26, 9, 8, 28, 2, 1, 31]]\n",
            "[[19, 5, 1, 31, 11], [15, 5, 12, 16, 29, 2, 14, 11], [26, 9, 8, 28, 2, 1, 31, 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9bp62GI96Ap",
        "outputId": "ec76503a-00bd-4c3a-9a49-8b39e8bc408b"
      },
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen=max_eng_seq_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_fra_seq_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_fra_seq_len, padding='post')\n",
        "\n",
        "print('영어 데이터의 크기(shape) :', np.shape(encoder_input))\n",
        "print('프랑스어 입력데이터의 크기 :', np.shape(decoder_input))\n",
        "print('프랑스어 출력데이터의 크기 :', np.shape(decoder_target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 데이터의 크기(shape) : (50000, 22)\n",
            "프랑스어 입력데이터의 크기 : (50000, 74)\n",
            "프랑스어 출력데이터의 크기 : (50000, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOsAn-4h-dP5",
        "outputId": "76dec070-f472-4380-e8c4-f59fc5ee616c"
      },
      "source": [
        "print(encoder_input[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19  3  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXjhncLj-hLK",
        "outputId": "6e778338-6f8c-45d9-9f7a-edc6b540753c"
      },
      "source": [
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)\n",
        "\n",
        "print('영어 데이터의 크기 :', np.shape(encoder_input))\n",
        "print('프랑스어 입력 데이터의 크기 :', np.shape(decoder_input))\n",
        "print('프랑스어 출력 데이터의 크기 :', np.shape(decoder_target))  # 샘플의 수 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 데이터의 크기 : (50000, 22, 52)\n",
            "프랑스어 입력 데이터의 크기 : (50000, 74, 73)\n",
            "프랑스어 출력 데이터의 크기 : (50000, 74, 73)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH8ldqjv-xFS",
        "outputId": "8f954735-262e-4e7b-a8c0-cdbe5a2df72c"
      },
      "source": [
        "n_of_val = 3000\n",
        "\n",
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]\n",
        "\n",
        "print('영어 학습데이터의 크기 :', np.shape(encoder_input))\n",
        "print('프랑스어 학습 입력데이터의 크기 :', np.shape(decoder_input))\n",
        "print('프랑스어 학습 출력데이터의 크기 :',np.shape(decoder_target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 학습데이터의 크기 : (50000, 22, 52)\n",
            "프랑스어 학습 입력데이터의 크기 : (50000, 74, 73)\n",
            "프랑스어 학습 출력데이터의 크기 : (50000, 74, 73)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tQRWIzL_qUn"
      },
      "source": [
        "## 모델 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFwyvzmR_ns9"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqVdJhYS_-Qk"
      },
      "source": [
        "# LSTM셀의 마지막 time step의 hidden state와 cell state를 디코더 LSTM의 첫번째 hidden state와 cell state전달해주자\n",
        "\n",
        "encoder_inputs = Input(shape=(None, eng_vocab_size))\n",
        "# 입력 텐서를 생성\n",
        "\n",
        "encoder_lstm = LSTM(units= 256, return_state=True)\n",
        "# hidden state 256인 LSTM을 생성\n",
        "\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "# 디코더로 전달할 hidden state, cell state를 리턴. encoder_output은 여기서는 불필요\n",
        "\n",
        "encoder_states = [state_h, state_c]\n",
        "# hidden state와 cell state를 다음 time step으로 전달하기 위해서 별도로 저장"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMZDez6FBAzV"
      },
      "source": [
        "decoder_inputs = Input(shape=(None, fra_vocab_size))\n",
        "# 입력 텐서 생성\n",
        "\n",
        "decoder_lstm = LSTM(units=256, return_sequences= True, return_state=True)\n",
        "# hidden state size 256 디코더 LSTM 생성\n",
        "\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
        "# decoder output는 모든 timestep의 hidden state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "895wAJedBu2l"
      },
      "source": [
        "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc6uViuWB0ih",
        "outputId": "a84a6d2a-7188-4672-9ba4-8882427cb657"
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 52)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 73)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 256), (None, 316416      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  337920      input_2[0][0]                    \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 73)     18761       lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 673,097\n",
            "Trainable params: 673,097\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBH6_P2-Cd_q",
        "outputId": "f49184f5-09b9-4a85-dff1-771c42b3ff7c"
      },
      "source": [
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), batch_size=128, epochs=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "368/368 [==============================] - 287s 767ms/step - loss: 0.9032 - val_loss: 0.7956\n",
            "Epoch 2/30\n",
            "368/368 [==============================] - 277s 752ms/step - loss: 0.5641 - val_loss: 0.6492\n",
            "Epoch 3/30\n",
            "368/368 [==============================] - 282s 767ms/step - loss: 0.4678 - val_loss: 0.5676\n",
            "Epoch 4/30\n",
            "368/368 [==============================] - 279s 758ms/step - loss: 0.4090 - val_loss: 0.5101\n",
            "Epoch 5/30\n",
            "368/368 [==============================] - 281s 762ms/step - loss: 0.3696 - val_loss: 0.4692\n",
            "Epoch 6/30\n",
            "368/368 [==============================] - 277s 752ms/step - loss: 0.3413 - val_loss: 0.4432\n",
            "Epoch 7/30\n",
            "368/368 [==============================] - 282s 765ms/step - loss: 0.3200 - val_loss: 0.4279\n",
            "Epoch 8/30\n",
            "368/368 [==============================] - 276s 751ms/step - loss: 0.3030 - val_loss: 0.4117\n",
            "Epoch 9/30\n",
            "368/368 [==============================] - 270s 733ms/step - loss: 0.2891 - val_loss: 0.4034\n",
            "Epoch 10/30\n",
            "368/368 [==============================] - 272s 739ms/step - loss: 0.2774 - val_loss: 0.3929\n",
            "Epoch 11/30\n",
            "368/368 [==============================] - 279s 759ms/step - loss: 0.2674 - val_loss: 0.3849\n",
            "Epoch 12/30\n",
            "368/368 [==============================] - 273s 742ms/step - loss: 0.2585 - val_loss: 0.3774\n",
            "Epoch 13/30\n",
            "368/368 [==============================] - 274s 744ms/step - loss: 0.2507 - val_loss: 0.3715\n",
            "Epoch 14/30\n",
            "368/368 [==============================] - 278s 756ms/step - loss: 0.2436 - val_loss: 0.3680\n",
            "Epoch 15/30\n",
            "368/368 [==============================] - 274s 745ms/step - loss: 0.2371 - val_loss: 0.3710\n",
            "Epoch 16/30\n",
            "368/368 [==============================] - 270s 734ms/step - loss: 0.2311 - val_loss: 0.3644\n",
            "Epoch 17/30\n",
            "368/368 [==============================] - 262s 713ms/step - loss: 0.2257 - val_loss: 0.3659\n",
            "Epoch 18/30\n",
            "368/368 [==============================] - 263s 714ms/step - loss: 0.2206 - val_loss: 0.3598\n",
            "Epoch 19/30\n",
            "368/368 [==============================] - 264s 718ms/step - loss: 0.2158 - val_loss: 0.3604\n",
            "Epoch 20/30\n",
            "260/368 [====================>.........] - ETA: 1:15 - loss: 0.2110"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa7Ftx7CFInU"
      },
      "source": [
        "1. 현재 charlevel로 번역기를 구현했는데 word-level로 번역기 완성하기\n",
        "2. 1번숙제에 실패하거나 포기하신분들은 seq2seq번역기 flow를 그려서 슬랙에 올리기 (자세히 변수까지)\n",
        "- 링크 참조 : https://wikidocs.net/86900"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWuQDJKAGNNK"
      },
      "source": [
        "### 모델 테스트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-z_Ny5LGPAZ"
      },
      "source": [
        "- 훈련 시에 학습해야 할 타겟 문장을 디코더 모델의 입력, 출력 시퀀스로 넣어 주고, 디코더 모델이 타겟 문장을 한꺼번에 출력하게 할 수 있습니다. 테스트 단계는 불가능!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vaG8KSOGVv7"
      },
      "source": [
        "- 테스트 단계에서 디코더 동작 순서\n",
        "  - 인코더에 입력 문장을 넣어 마지막 time step의 hidden, cell state를 얻는다.\n",
        "  - 토큰인 \\t를 디코더에 입력한다.\n",
        "  - 이전 timestep의 출력층의 예측 결과를 현재 timestep의 입력으로 한다.\n",
        "  - 3을 반복하다가 토큰인 \\n가 예측되면 이를 중단한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKkfUBzsDRhg"
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n",
        "encoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obo2Ar6WGnjE"
      },
      "source": [
        "decoder_state_input_h = Input(shape=(256,))\n",
        "# 이전 timestep의 hidden state를 저장하는 텐서\n",
        "\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "# 이전 timestep의 cell state를 저장하는 텐서\n",
        "\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
        "\n",
        "# decoder_state_inputs를 현재 time step의 초기상태로 사용\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
        "\n",
        "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
        "decoder_states = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPiHowsdH2uA"
      },
      "source": [
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model= Model(inputs=[decoder_inputs] + decoder_state_inputs, outputs=[decoder_outputs]+decoder_states)\n",
        "decoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KwnA9vXH441"
      },
      "source": [
        "eng2idx = eng_tokenizer.word_index\n",
        "fra2idx = fra_tokenizer.word_index\n",
        "idx2eng = eng_tokenizer.index_word\n",
        "idx2fra = fra_tokenizer.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9JnXX93H_Vl"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 상태를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "  target_seq = np.zeros((1, 1, fra_vocab_size))\n",
        "  target_seq[0, 0, fra2idx['\\t']] =1\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "\n",
        "  # stop condition이 True가 될떄까지 루프 반복\n",
        "  while not stop_condition:\n",
        "    # 이전 시점의 상태 state_value를 현 시점의 초기 상태로 사용\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq]+ states_value)\n",
        "\n",
        "    # 예측 결과를 문자로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = idx2fra[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    # <eos>에 도달하거나 최대 길이를 넘으면 중단\n",
        "    if (sampled_char == '\\n' or\n",
        "        len(decoded_sentence) > max_fra_seq_len):\n",
        "      stop_condition = True\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1, 1, fra_vocab_size))\n",
        "    target_seq[0, 0, sampled_token_index] =1\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "  return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD0PSBQ1KOoY"
      },
      "source": [
        "import numpy as np\n",
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  # 입력 문장의 인덱스 (자유롭게 바꿔서 테스트 해보세요!)\n",
        "  input_seq = encoder_input[seq_index: seq_index +1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print(35 * \"-\")\n",
        "  print('입력 문장 :', lines.eng[seq_index])\n",
        "  print('정답 문장 :', lines.fra[seq_index][1:len(lines.fra[seq_index])-1])\n",
        "  # '\\t'와 '\\n'을 빼고 출력\n",
        "  print('번역기가 번역한 문장 :', decoded_sentence[:len(decoded_sentence)-1])\n",
        "  # '\\n'을 빼고 출력"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}